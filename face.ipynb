{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08a539",
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2 as cv\n",
    "\n",
    "class MultipleTarget:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        \"\"\"\n",
    "        # 加载训练模型\n",
    "        self.model = torch.hub.load('./', 'custom', path='./face.pt', source='local')\n",
    "        # 设置阈值\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.conf = 0.52  # confidence threshold (0-1)\n",
    "        self.model.iou = 0.45  # NMS IoU threshold (0-1)\n",
    "        # 加载摄像头\n",
    "        self.cap = cv.VideoCapture(0)  # 0表示默认摄像头，如果有多个摄像头，可以尝试其他索引\n",
    "\n",
    "    def draw(self, list1, image_temp):\n",
    "        for temp in list1:\n",
    "            name = temp[6]  # 取出标签名\n",
    "            conf = temp[4]\n",
    "            temp = temp[:4].astype('int')  # 转成int\n",
    "            cv.rectangle(image_temp, (temp[0], temp[1]), (temp[2], temp[3]), (0, 0, 255), 3)  # 框出识别物体\n",
    "            cv.putText(image_temp,f\"{name} {conf:.2f}\", (int(temp[0]-10), int(temp[1]-10)), cv.FONT_ITALIC, 1, (0, 255, 0), 2)\n",
    "\n",
    "    def detect(self):\n",
    "        \"\"\"\n",
    "        目标检测\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            ret,frame = self.cap.read()  # 读取视频流帧\n",
    "\n",
    "            img = frame\n",
    "            # Inference\n",
    "            results = self.model(img)\n",
    "            # Results\n",
    "            results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "            pd1 = results.xyxy[0]\n",
    "            pd = results.pandas().xyxy[0]\n",
    "            print(\"ljc\")\n",
    "            print(pd[:4])\n",
    "            print(\"ljc\")\n",
    "\n",
    "            person_list = pd[pd['name'] == 'face'].to_numpy()\n",
    "\n",
    "            self.draw(person_list, img)\n",
    "\n",
    "            cv.imshow('results', img)\n",
    "            if cv.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "test = MultipleTarget()\n",
    "test.detect()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "29497ae34972324e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2 as cv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:11:23.134944Z",
     "start_time": "2024-03-26T16:11:23.128424Z"
    }
   },
   "id": "c921e62562fae46",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032e899",
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import math\n",
    "# from cv2 import cv2\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from EAR import eye_aspect_ratio\n",
    "from MAR import mouth_aspect_ratio\n",
    "from HeadPose import getHeadTiltAndCoords\n",
    "\n",
    "# 初始化 dlib 的面部检测器（基于 HOG），然后创建\n",
    "# 面部地标预测器\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\n",
    "    './dlib_shape_predictor/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# 初始化视频流并休眠一会儿，让摄像机传感器预热\n",
    "print(\"[INFO] initializing camera...\")\n",
    "\n",
    "video_file_path = r\"F:\\数据集\\YawDD.rar\\YawDD\\YawDD dataset\\Dash\\Female\\4-FemaleNoGlasses.avi\"\n",
    "# vs = cv2.VideoCapture(video_file_path)\n",
    "vs = cv2.VideoCapture(0)\n",
    "# vs =  VideoStream(src=\"F:\\数据集\\YawDD.rar\\YawDD\\YawDD dataset\\Dash\\Male\\2-MaleGlasses.avi\").start()\n",
    "# vs = VideoStream(usePiCamera=True).start() # Raspberry Pi\n",
    "time.sleep(2.0)\n",
    "model = torch.hub.load('./', 'custom', path='./face.pt', source='local')\n",
    "# 设置阈值\n",
    "model.conf = 0.52  # confidence threshold (0-1)\n",
    "model.iou = 0.45  # NMS IoU threshold (0-1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "# 400x225 to 1024x576\n",
    "frame_width = 1024\n",
    "frame_height = 576\n",
    "Roll = 0\n",
    "Rolleye = 0\n",
    "Rollmouth = 0\n",
    "\n",
    "# 循环播放视频流中的帧\n",
    "# 2D 图像点。如果更改图像，则需要更改矢量\n",
    "image_points = np.array([\n",
    "    (359, 391),     # Nose tip 34\n",
    "    (399, 561),     # Chin 9\n",
    "    (337, 297),     # Left eye left corner 37\n",
    "    (513, 301),     # Right eye right corne 46\n",
    "    (345, 465),     # Left Mouth corner 49\n",
    "    (453, 469)      # Right mouth corner 55\n",
    "], dtype=\"double\")\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "# 设置阈值\n",
    "EYE_AR_THRESH = 0.25\n",
    "MOUTH_AR_THRESH = 0.79\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "COUNTER = 0\n",
    "\n",
    "# 为嘴巴获取面部地标索引\n",
    "(mStart, mEnd) = (49, 68)\n",
    "\n",
    "while True:\n",
    "    # 从线程视频流中抓取帧，调整其大小至\n",
    "    # 最大宽度为 400 像素，并将其转换为\n",
    "    # 灰度\n",
    "    \n",
    "    ret,frame = vs.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=640, height=576)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    results = model(gray)\n",
    "    results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "    pd1 = results.xyxy[0]\n",
    "    pd = results.pandas().xyxy[0]\n",
    "    \n",
    "    person_list = pd[pd['name'] == 'face'].to_numpy()\n",
    "    size = gray.shape\n",
    "    \n",
    "    if not pd.empty and 'xmin' in pd.columns and not pd['xmin'].isnull().all():\n",
    "        xmin = int(pd['xmin'].values[0])\n",
    "        ymin = int(pd['ymin'].values[0])\n",
    "        xmax = int(pd['xmax'].values[0])\n",
    "        ymax = int(pd['ymax'].values[0])\n",
    "        # 其他操作...\n",
    "    else:\n",
    "        # 处理空列的情况或者跳过当前循环\n",
    "        pass\n",
    "        # detect faces in the grayscale frame\n",
    "    rects = [dlib.rectangle(left=xmin, top=ymin, right=xmax, bottom=ymax)]\n",
    "\n",
    "   \n",
    "    # 检查是否检测到人脸，如果是，则绘制帧上人脸的总数。\n",
    "    # 帧上的人脸数量\n",
    "    if rects is not None:\n",
    "        text = \"{} face(s) found\".format(len(rects))\n",
    "        cv2.putText(frame, text, (10, 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # 循环检测人脸\n",
    "    for rect in rects:\n",
    "        # 计算面的包围盒并将其绘制在\n",
    "        # 边框\n",
    "        (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1)\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # 确定面部区域的面部地标，然后\n",
    "        # 将面部地标 (x, y) 坐标转换为 NumPy数组\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        # 将两只眼睛的长宽比平均到一起\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        # 计算左眼和右眼的凸壳，然后\n",
    "        # 可视化每只眼睛\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        # 计算左眼和右眼的凸壳，然后\n",
    "        # 可视化每只眼睛\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "            Rolleye += 1\n",
    "            # 如果闭眼的次数足够多\n",
    "            # 则显示警告\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                cv2.putText(frame, \"Eyes Closed!\", (500, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            # 否则，眼球长宽比不会低于眨眼\n",
    "            # 阈值，因此重置计数器和警报\n",
    "        else:\n",
    "            COUNTER = 0\n",
    "\n",
    "        mouth = shape[mStart:mEnd]\n",
    "\n",
    "        mouthMAR = mouth_aspect_ratio(mouth)\n",
    "        mar = mouthMAR\n",
    "        # 计算嘴巴的凸壳，然后\n",
    "        # 可视化嘴巴\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "\n",
    "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "        cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (650, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "         # 如果嘴巴张开，则绘制文字\n",
    "        if mar > MOUTH_AR_THRESH:\n",
    "            Rollmouth +=1\n",
    "            cv2.putText(frame, \"Yawning!\", (800, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "        Roll += 1\n",
    "            # 当检测满150帧时，计算模型得分\n",
    "        perclos = (Rolleye/Roll) + (Rollmouth/Roll)*0.2\n",
    "        # 在前端UI输出perclos值\n",
    "        cv2.putText(frame, \"Perclos: {:.2f}\".format(perclos), (650, 220), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        if perclos > 0.38:\n",
    "            cv2.putText(frame, \"tired\".format(perclos), (800, 220), \n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"alert\".format(perclos), (800, 220), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        if Roll == 150:\n",
    "            # 归零\n",
    "            # 将三个计数器归零\n",
    "            # 重新开始新一轮的检测\n",
    "            Roll = 0\n",
    "            Rolleye = 0\n",
    "            Rollmouth = 0\n",
    "\n",
    "\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw each of them\n",
    "        for (i, (x, y)) in enumerate(shape):\n",
    "            if i == 33:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[0] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            elif i == 8:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[1] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            elif i == 36:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[2] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            elif i == 45:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[3] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            elif i == 48:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[4] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            elif i == 54:\n",
    "                # something to our key landmarks\n",
    "                # save to our new key point list\n",
    "                # i.e. keypoints = [(i,(x,y))]\n",
    "                image_points[5] = np.array([x, y], dtype='double')\n",
    "                # write on frame in Green\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "            else:\n",
    "                # everything to all other landmarks\n",
    "                # write on frame in Red\n",
    "                cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "        #Draw the determinant image points onto the person's face\n",
    "        for p in image_points:\n",
    "            cv2.circle(frame, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)\n",
    "\n",
    "        (head_tilt_degree, start_point, end_point, \n",
    "            end_point_alt) = getHeadTiltAndCoords(size, image_points, frame_height)\n",
    "\n",
    "        cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "        cv2.line(frame, start_point, end_point_alt, (0, 0, 255), 2)\n",
    "\n",
    "        if head_tilt_degree:\n",
    "            cv2.putText(frame, 'Head Tilt Degree: ' + str(head_tilt_degree[0]), (170, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        # extract the mouth coordinates, then use the\n",
    "        # coordinates to compute the mouth aspect ratio\n",
    "    # show the frameq\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# print(image_points)\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15e480",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-26T15:28:28.163729Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d5010",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-26T15:28:28.164848Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
